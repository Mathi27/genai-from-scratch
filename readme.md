# Generative AI — Built from First Principles

[ Open Source Initiative]
> A structured, first-principles learning log for Generative AI — built incrementally, shared publicly.

I’m a 24-year-old Master’s student from **BITS Pilani , India**.  
This repository documents my **daily progress** learning Generative AI **from fundamentals to production concepts**.

This is **not** a tutorial dump or framework showcase.  
It focuses on **core concepts you must understand** to start and grow in GenAI — explained incrementally, with engineering depth.

---

## Why This Repo Exists

- To learn GenAI **the way engineers approach systems**
- To prioritize **first principles over tools**
- To avoid hype-driven, shallow learning
- To maintain a **public, evolving knowledge log**
- To help others start GenAI with clarity

> Contents are **intentionally evolving** and subject to refinement.

---

## Target Audience

- Students entering GenAI
- Software / ML / ECE engineers transitioning into LLMs
- Learners who want **conceptual clarity before scaling**
- Anyone confused by buzzwords like *LLMs, RAG, Agents, Fine-tuning*

---

## Learning Philosophy

- Incremental depth
- System-level thinking
- Trade-offs > tools
- Intuition → math → implementation
- Learning in public

## Topic Roadmap (Living Document)

> Topics are added incrementally.  
> Order, depth, and structure may evolve as understanding improves.

---

### 00. Prerequisites
| Topic | Status |
|-----|--------|
| Python essentials for GenAI | Published |
| ML vs DL vs GenAI | Published |
| Probability intuition (softmax, entropy) | Published |
| Linear algebra intuition (vectors, dot product, cosine similarity) | Published |
| Why GPUs & accelerators matter | Published |
| Numerical precision (FP32 vs FP16 vs INT8) | Published |

---

### 01. LLM Fundamentals
| Topic | Status |
|-----|--------|
| What is a Large Language Model | Published |
| Evolution: n-grams → RNN → Transformer | Planned |
| Tokens and tokenization | Planned |
| Vocabulary size & token efficiency | Planned |
| Embeddings: geometry and meaning | Planned |
| Attention mechanism (intuition → math) | Planned |
| Self-attention vs cross-attention | Planned |
| Transformer architecture walkthrough | Planned |
| Pretraining vs inference | Planned |
| Why scale works (scaling laws intuition) | Planned |

---

### 02. Prompt Engineering
| Topic | Status |
|-----|--------|
| What prompting actually is | Planned |
| Zero-shot vs few-shot prompting | Planned |
| System vs user prompts | Planned |
| Prompt templates and reuse | Planned |
| Chain-of-Thought reasoning | Planned |
| ReAct prompting | Planned |
| Prompt injection risks | Planned |
| Prompt debugging mindset | Planned |

---

### 03. LLM Inference & Decoding
| Topic | Status |
|-----|--------|
| Inference pipeline overview | Planned |
| Logits → probabilities | Planned |
| Temperature | Planned |
| Top-k sampling | Planned |
| Top-p (nucleus) sampling | Planned |
| Greedy vs beam search | Planned |
| Determinism vs creativity trade-offs | Planned |
| Latency vs quality vs cost | Planned |

---

### 04. Retrieval Augmented Generation (RAG)
| Topic | Status |
|-----|--------|
| Why hallucinations happen | Planned |
| Limitations of pure LLMs | Planned |
| What problem RAG solves | Planned |
| Embedding generation | Planned |
| Vector similarity search | Planned |
| Chunking strategies | Planned |
| Indexing & retrieval pipelines | Planned |
| RAG failure modes | Planned |
| RAG vs fine-tuning | Planned |

---

### 05. Agents & Tool Use
| Topic | Status |
|-----|--------|
| What is an LLM agent | Planned |
| Tool calling fundamentals | Planned |
| Planning vs execution | Planned |
| Memory in agents | Planned |
| Single-agent systems | Planned |
| Multi-agent coordination | Planned |
| Agent reliability & failure cases | Planned |

---

### 06. Fine-Tuning
| Topic | Status |
|-----|--------|
| When fine-tuning is necessary | Planned |
| Prompting vs RAG vs fine-tuning | Planned |
| Data requirements | Planned |
| Supervised fine-tuning (SFT) | Planned |
| Parameter-efficient tuning (LoRA, QLoRA) | Planned |
| Cost & compute considerations | Planned |

---

### 07. Evaluation & Safety
| Topic | Status |
|-----|--------|
| Why LLM evaluation is hard | Planned |
| Automatic vs human evaluation | Planned |
| Task-based evaluation | Planned |
| Hallucination detection | Planned |
| Bias and fairness | Planned |
| Safety & misuse risks | Planned |

---

### 08. LLMOps & Production
| Topic | Status |
|-----|--------|
| Deployment patterns | Planned |
| API vs self-hosted models | Planned |
| Monitoring outputs | Planned |
| Drift detection | Planned |
| Cost optimization strategies | Planned |
| Prompt and model versioning | Planned |
| Incident analysis in production | Planned |

---

### 09. Projects (Applied Learning)
| Project | Focus |
|------|------|
| Minimal LLM chatbot | Core LLM usage |
| RAG-based QA system | Retrieval pipelines |
| Tool-using agent | Planning & execution |
| End-to-end GenAI application | Production concerns |
